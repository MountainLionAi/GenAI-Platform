#!/usr/bin/env python3
"""
æ™ºèƒ½æœç´¢ç ”ç©¶åŠ©æ‰‹ - é«˜å¹¶å‘ä¼˜åŒ–ç‰ˆ
åŠŸèƒ½ï¼šåŸºäºèŠå¤©è®°å½•ç”Ÿæˆç ”ç©¶é—®é¢˜ï¼Œå¹¶ä½¿ç”¨OpenAI Responses APIçš„Web SearchåŠŸèƒ½è¿›è¡Œå¹¶å‘æœç´¢
ä¼˜åŒ–ï¼šå…¨å¼‚æ­¥å®ç°ã€è¿æ¥æ± å¤ç”¨ã€é€Ÿç‡é™åˆ¶ã€å¹¶å‘æ§åˆ¶
"""

import os
import json
import asyncio
from typing import List, Dict, Any, Optional, ClassVar
from dataclasses import dataclass, field
from dotenv import load_dotenv
from anthropic import AsyncAnthropic
from openai import AsyncOpenAI
import logging
from datetime import datetime, timezone
from genaipf.dispatcher.utils import ANTHROPIC_API_KEY, OPENAI_API_KEY
import time
from aiolimiter import AsyncLimiter
from contextlib import asynccontextmanager

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class Question:
    """é—®é¢˜æ•°æ®ç»“æ„"""
    main_question: str
    sub_questions: List[str] = field(default_factory=list)
    time_requirement: str = "æœ€æ–°"
    full_question: str = ""
    search_context_size: str = "high"  # high, medium, low
    
    def __post_init__(self):
        if not self.full_question:
            self.full_question = self._generate_full_question()
    
    def _generate_full_question(self) -> str:
        """ç”Ÿæˆå®Œæ•´çš„é—®é¢˜æè¿°"""
        parts = [self.main_question]
        if self.sub_questions:
            parts.append("\nå…·ä½“åŒ…æ‹¬ï¼š")
            parts.extend(f"- {sq}" for sq in self.sub_questions)
        return "\n".join(parts)

@dataclass
class SearchResult:
    """æœç´¢ç»“æœæ•°æ®ç»“æ„"""
    question: Question
    answer: str = ""
    success: bool = True
    error: Optional[str] = None
    search_time: float = 0.0

class APIClientManager:
    """å…¨å±€APIå®¢æˆ·ç«¯ç®¡ç†å™¨ - å•ä¾‹æ¨¡å¼"""
    _instance: ClassVar[Optional['APIClientManager']] = None
    _lock: ClassVar[asyncio.Lock] = asyncio.Lock()
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not hasattr(self, '_initialized'):
            self._initialized = True
            self._claude_client: Optional[AsyncAnthropic] = None
            self._openai_client: Optional[AsyncOpenAI] = None
            
            # é€Ÿç‡é™åˆ¶å™¨
            # Claude: æ ¹æ®å®˜æ–¹é™åˆ¶ï¼Œå‡è®¾æ¯åˆ†é’Ÿ50ä¸ªè¯·æ±‚
            self._claude_limiter = AsyncLimiter(50, 60)
            # OpenAI: æ ¹æ®å®˜æ–¹é™åˆ¶ï¼Œå‡è®¾æ¯åˆ†é’Ÿ100ä¸ªè¯·æ±‚
            self._openai_limiter = AsyncLimiter(100, 60)
            
            # å¹¶å‘æ§åˆ¶ä¿¡å·é‡
            self._claude_semaphore = asyncio.Semaphore(10)  # æœ€å¤š10ä¸ªå¹¶å‘Claudeè¯·æ±‚
            self._openai_semaphore = asyncio.Semaphore(20)  # æœ€å¤š20ä¸ªå¹¶å‘OpenAIè¯·æ±‚
    
    @property
    def claude_client(self) -> AsyncAnthropic:
        """è·å–Claudeå®¢æˆ·ç«¯ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._claude_client is None:
            api_key = ANTHROPIC_API_KEY
            if not api_key:
                raise ValueError("ANTHROPIC_API_KEYæœªåœ¨ç¯å¢ƒå˜é‡ä¸­æ‰¾åˆ°")
            self._claude_client = AsyncAnthropic(api_key=api_key)
        return self._claude_client
    
    @property
    def openai_client(self) -> AsyncOpenAI:
        """è·å–OpenAIå®¢æˆ·ç«¯ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self._openai_client is None:
            api_key = OPENAI_API_KEY
            if not api_key:
                raise ValueError("OPENAI_API_KEYæœªåœ¨ç¯å¢ƒå˜é‡ä¸­æ‰¾åˆ°")
            self._openai_client = AsyncOpenAI(api_key=api_key)
        return self._openai_client
    
    @asynccontextmanager
    async def claude_rate_limit(self):
        """Claude APIé€Ÿç‡é™åˆ¶ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        async with self._claude_semaphore:
            async with self._claude_limiter:
                yield
    
    @asynccontextmanager
    async def openai_rate_limit(self):
        """OpenAI APIé€Ÿç‡é™åˆ¶ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        async with self._openai_semaphore:
            async with self._openai_limiter:
                yield
    
    async def close(self):
        """å…³é—­æ‰€æœ‰å®¢æˆ·ç«¯è¿æ¥"""
        if self._claude_client:
            await self._claude_client.close()
        if self._openai_client:
            await self._openai_client.close()

class ResearchAssistant:
    """ç ”ç©¶åŠ©æ‰‹ä¸»ç±» - é«˜å¹¶å‘ä¼˜åŒ–ç‰ˆ"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç ”ç©¶åŠ©æ‰‹"""
        # ä½¿ç”¨å…¨å±€å®¢æˆ·ç«¯ç®¡ç†å™¨
        self.client_manager = APIClientManager()
        
        # è®¾ç½®æ—¶åŒº
        self.timezone = os.getenv('TIMEZONE', 'UTC')
        
        # ç”¨äºæ§åˆ¶æ•´ä½“å¹¶å‘çš„ä¿¡å·é‡ï¼ˆé¿å…åŒæ—¶å¤„ç†è¿‡å¤šç”¨æˆ·è¯·æ±‚ï¼‰
        self._user_request_semaphore = asyncio.Semaphore(30)  # æœ€å¤šåŒæ—¶å¤„ç†30ä¸ªç”¨æˆ·è¯·æ±‚
        
        logger.info("ç ”ç©¶åŠ©æ‰‹åˆå§‹åŒ–æˆåŠŸï¼ˆé«˜å¹¶å‘ç‰ˆï¼‰")
    
    def get_current_time(self) -> Dict[str, str]:
        """è·å–å½“å‰æ—¶é—´ä¿¡æ¯"""
        now = datetime.now()
        return {
            'datetime': now.strftime('%Y-%m-%d %H:%M:%S'),
            'date': now.strftime('%Y-%m-%d'),
            'year': str(now.year),
            'month': str(now.month),
            'day': str(now.day),
            'hour': str(now.hour),
            'minute': str(now.minute),
            'month_name': now.strftime('%B'),
            'weekday': now.strftime('%A'),
            'timestamp': int(time.time())
        }
    
    async def generate_research_questions(self, chat_history: str) -> List[Question]:
        """ä½¿ç”¨Claudeç”Ÿæˆéœ€è¦ç ”ç©¶çš„é—®é¢˜ï¼ˆå¼‚æ­¥ç‰ˆï¼‰"""
        current_time = self.get_current_time()
        
        prompt = f"""
å½“å‰æ—¶é—´ï¼š{current_time['datetime']} æ—¶åŒºä¸ºï¼š{self.timezone}ï¼ˆè¯·åŸºäºå½“å‰æ—¶é—´å¯¹é—®é¢˜çš„æ—¶æ•ˆæ€§ä½œå‡ºæ˜ç¡®è¦æ±‚ï¼‰

åŸºäºä»¥ä¸‹ç”¨æˆ·å’Œchatbotçš„èŠå¤©è®°å½•ï¼ŒæŠŠç”¨æˆ·æ ¹æœ¬éœ€æ±‚æ‹†è§£ï¼Œåˆ†æˆå­é—®é¢˜å¹¶é€šè¿‡ç½‘ç»œæœç´¢è§£å†³å­é—®é¢˜ï¼Œä»è€Œèƒ½ç²¾å‡†è§£å†³ç”¨æˆ·éœ€æ±‚ã€‚

èŠå¤©è®°å½•ï¼š
{chat_history}

é‡è¦æç¤ºï¼š
1. æ‰€æœ‰é—®é¢˜å¿…é¡»åŸºäºå½“å‰æ—¶é—´ï¼š{current_time['datetime']}ï¼Œæ—¶åŒºä¸ºï¼š{self.timezone}æ¥ç”Ÿæˆ
2. å¦‚æœç”¨æˆ·è¯¢é—®"æœ€è¿‘"ã€"å½“å‰"ã€"ç°åœ¨"ç­‰ä¿¡æ¯ï¼Œè¦æŸ¥è¯¢å½“å‰æ—¶é—´ï¼š{current_time['datetime']}ï¼Œæ—¶åŒºä¸ºï¼š{self.timezone}ä¸‹çš„æœ€æ–°æƒ…å†µï¼Œæ ¹æ®æƒ…å†µå¢å¼ºå®æ•ˆæ€§
3. ä¸è¦ç”Ÿæˆå…³äºè¿‡å»å¹´ä»½çš„é—®é¢˜ï¼Œé™¤éç”¨æˆ·æ˜ç¡®è¦æ±‚å†å²æ•°æ®å¯¹æ¯”
4. å¯¹äºæŠ•èµ„ã€å¸‚åœºã€æŠ€æœ¯ç­‰å¿«é€Ÿå˜åŒ–çš„é¢†åŸŸï¼Œåªå…³æ³¨æœ€è¿‘çš„ä¿¡æ¯

è¦æ±‚ï¼š
1. æ™ºèƒ½åˆ†æç”¨æˆ·éœ€æ±‚çš„å¤æ‚åº¦ï¼ˆæ ¹æ®é—®é¢˜éš¾åº¦åˆ¤æ–­éœ€è¦æœç´¢çš„ä¸»é¢˜æ•°é‡ï¼‰ï¼š
   - ç®€å•æŸ¥è¯¢ï¼ˆå¦‚å¤©æ°”ã€è‚¡ä»·ã€å¸ä»·ï¼‰ï¼šç”Ÿæˆ1ä¸ªç²¾å‡†é—®é¢˜ä¸»é¢˜
   - ä¸­ç­‰å¤æ‚åº¦ï¼ˆå¦‚äº§å“æ¯”è¾ƒã€æ–°é—»äº‹ä»¶ï¼‰ï¼šç”Ÿæˆ2-3ä¸ªç›¸å…³é—®é¢˜ä¸»é¢˜
   - é«˜å¤æ‚åº¦ï¼ˆå¦‚å¸‚åœºåˆ†æã€æŠ€æœ¯ç ”ç©¶ï¼‰ï¼šç”Ÿæˆ3-5ä¸ªæ·±åº¦é—®é¢˜ä¸»é¢˜

2. é—®é¢˜è®¾è®¡åŸåˆ™ï¼š
   - æ¯ä¸ªé—®é¢˜ä¸»é¢˜å¿…é¡»æ˜ç¡®åŒ…å«æ—¶é—´èŒƒå›´ï¼ˆå¦‚ï¼š2025å¹´6æœˆã€æœ¬å‘¨ã€è¿‡å»7å¤©ã€æœ¬æ—¥ã€ä¸€å°æ—¶å†…ã€å®æ—¶ç­‰ï¼‰
   - é¿å…è¿‡äºå®½æ³›æˆ–æŠ½è±¡çš„é—®é¢˜
   - ç¡®ä¿å…¨éƒ¨é—®é¢˜ä¸»é¢˜ä»¥åŠå…·ä½“å­é—®é¢˜ä¹‹é—´æœ‰é€»è¾‘å…³è”ä½†æŸ¥è¯¢å†…å®¹ä¸é‡å¤ã€‚
   - å¯¹äºéœ€è¦ç¡®è®¤è™šæ‹Ÿå¸ä»·æ ¼æˆ–è€…è‚¡ä»·æŸ¥è¯¢ï¼Œå¿…é¡»ä¸ºä¸€ä¸ªç‹¬ç«‹çš„å®æ—¶é—®é¢˜ä¸»é¢˜ï¼Œä¸èƒ½åœ¨é—®é¢˜ä¸»é¢˜ä¸åŒ…å«è™šæ‹Ÿå¸ä»·æ ¼æƒ…å†µä¸‹ï¼Œå…·ä½“å­é—®é¢˜åŒ…å«ä»·æ ¼æˆ–è€…æŒ‡æ ‡ç›¸å…³çš„ã€‚å¦åˆ™è·å¾—çš„ä»·æ ¼ç»“æœä¼šä¸å‡†ã€‚
   - å¯¹äºå¤æ‚é—®é¢˜ä¸»é¢˜ï¼Œå¯å°†å¤§é—®é¢˜è¿›ä¸€æ­¥ç»†åŒ–ä¸º1-3ä¸ªå…·ä½“å­é—®é¢˜

3. æ—¶æ•ˆæ€§è¦æ±‚åˆ†ç±»ï¼š
   - å®æ—¶æ•°æ®ï¼šè‚¡ä»·ã€æ±‡ç‡ã€å¤©æ°”ç­‰ï¼ˆæ ‡è®°ä¸º"å®æ—¶"ï¼‰
   - è¿‘æœŸä¿¡æ¯ï¼šæ–°é—»ã€äº‹ä»¶ã€è¶‹åŠ¿ç­‰ï¼ˆæ ‡è®°ä¸º"24å°æ—¶å†…"ã€"æœ¬å‘¨"æˆ–"æœ¬æœˆ"ï¼‰
   - ç›¸å¯¹ç¨³å®šï¼šæŠ€æœ¯æ–‡æ¡£ã€å†å²äº‹ä»¶ç­‰ï¼ˆæ ‡è®°ä¸º"æœ€æ–°"ï¼‰

4. æœç´¢æ·±åº¦å»ºè®®ï¼š
   - ç®€å•äº‹å®æŸ¥è¯¢ï¼šlow
   - éœ€è¦å¯¹æ¯”åˆ†æï¼šmedium
   - éœ€è¦æ·±åº¦ç ”ç©¶ï¼šhigh

è¯·ä»¥ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š
```json
[
    {{
        "main_question": "æ ¸å¿ƒé—®é¢˜ä¸»é¢˜ï¼ˆå¿…é¡»åŒ…å«æ˜ç¡®çš„æ—¶é—´èŒƒå›´ä»¥åŠæ ‡å‡ºå½“å‰æ—¶é—´ï¼‰",
        "sub_questions": ["å…·ä½“å­é—®é¢˜1", "å…·ä½“å­é—®é¢˜2"],
        "time_requirement": "æ—¶æ•ˆæ€§è¦æ±‚ï¼ˆå¦‚ï¼šå®æ—¶ã€24å°æ—¶å†…ã€æœ¬å‘¨ã€æœ¬æœˆï¼‰",
        "search_context_size": "æœç´¢æ·±åº¦ï¼ˆhigh/medium/lowï¼‰",
        "full_question": "åŒ…å«æ‰€æœ‰ç»†èŠ‚å’Œæ—¶é—´èŒƒå›´çš„å®Œæ•´é—®é¢˜æè¿°"
    }}
]
```

"""
        
        try:
            # ä½¿ç”¨é€Ÿç‡é™åˆ¶
            async with self.client_manager.claude_rate_limit():
                response = await self.client_manager.claude_client.messages.create(
                    model="claude-sonnet-4-20250514",
                    max_tokens=2000,
                    temperature=0.3,
                    messages=[{"role": "user", "content": prompt}]
                )
            
            content = response.content[0].text
            
            # æå–JSON
            start_idx = content.find('[')
            end_idx = content.rfind(']') + 1
            
            if start_idx != -1 and end_idx > start_idx:
                json_str = content[start_idx:end_idx]
                questions_data = json.loads(json_str)
                
                questions = []
                for q_data in questions_data:
                    question = Question(
                        main_question=q_data['main_question'],
                        sub_questions=q_data.get('sub_questions', []),
                        time_requirement=q_data.get('time_requirement', 'æœ€æ–°'),
                        search_context_size=q_data.get('search_context_size', 'high'),
                        full_question=q_data.get('full_question', '')
                    )
                    questions.append(question)
                
                logger.info(f"æˆåŠŸç”Ÿæˆ{len(questions)}ä¸ªç ”ç©¶é—®é¢˜")
                return questions
            else:
                raise ValueError("æ— æ³•è§£æClaudeå“åº”ä¸­çš„JSON")
                
        except Exception as e:
            logger.error(f"ç”Ÿæˆé—®é¢˜æ—¶å‡ºé”™: {str(e)}")
            # è¿”å›é»˜è®¤é—®é¢˜
            return [Question(
                main_question="åŸºäºèŠå¤©è®°å½•çš„ç›¸å…³ä¿¡æ¯æŸ¥è¯¢",
                time_requirement="æœ€æ–°",
                search_context_size="medium"
            )]
    
    async def search_single_question(self, question: Question) -> SearchResult:
        """ä½¿ç”¨OpenAI Responses APIçš„Web SearchåŠŸèƒ½æœç´¢å•ä¸ªé—®é¢˜ï¼ˆå¼‚æ­¥ç‰ˆï¼‰"""
        start_time = time.time()
        current_time = self.get_current_time()
        
        try:
            # è®¡ç®—ä¸Šä¸ªæœˆ
            current_month_int = int(current_time['month'])
            current_year_int = int(current_time['year'])
            previous_month = current_month_int - 1 if current_month_int > 1 else 12
            previous_year = current_year_int if current_month_int > 1 else current_year_int - 1
            
            # æ„å»ºå¢å¼ºçš„æœç´¢æŸ¥è¯¢
            search_prompt = f"""
å½“å‰ç²¾ç¡®æ—¶é—´ï¼š{current_time['datetime']} {self.timezone}
ä»Šå¤©æ˜¯ï¼š{current_time['year']}å¹´{current_time['month']}æœˆ{current_time['day']}æ—¥ {current_time['weekday']} {current_time['hour']}æ—¶{current_time['minute']}åˆ†

è¯·æœç´¢ä»¥ä¸‹é—®é¢˜çš„ç­”æ¡ˆï¼š

{question.full_question}

â° æ—¶æ•ˆæ€§è¦æ±‚ï¼š{question.time_requirement}

ğŸ” æœç´¢åŠæ—¶æ€§è¦æ±‚ï¼ˆé‡è¦ï¼‰ï¼š
1. **å®æ—¶æ•°æ®ç±»**ï¼ˆè‚¡ä»·ã€å¸ä»·ã€æ±‡ç‡ã€æŒ‡æ•°ï¼‰ï¼š
   - å¿…é¡»æ˜¯{current_time['year']}å¹´{current_time['month']}æœˆ{current_time['day']}æ—¥{current_time['hour']}æ—¶{current_time['minute']}åˆ†å‰å10åˆ†é’Ÿå†…çš„æ•°æ®
   - ä¼˜å…ˆæŸ¥æ‰¾ä¸»è¦äº¤æ˜“æ‰€/å®˜æ–¹æ•°æ®æºçš„å®æ—¶æŠ¥ä»·ï¼Œè™šæ‹Ÿå¸ä»·æ ¼æŸ¥è¯¢é€šè¿‡ï¼šhttps://coinmarketcap.com/
   - å¦‚æœæ•°æ®è¶…è¿‡30åˆ†é’Ÿï¼Œæ˜ç¡®æ ‡æ³¨"æ•°æ®å¯èƒ½å·²è¿‡æ—¶"
   - ä¸è¦é‡‡ç”¨æ–°é—»åª’ä½“æ–‡ç« å†…åŒ…å«çš„è¿‡æ—¶ä»·æ ¼ä¿¡æ¯

2. **çªå‘æ–°é—»ç±»**ï¼ˆæ–°é—»äº‹ä»¶ã€å…¬å‘Šã€çªå‘æ¶ˆæ¯ï¼‰ï¼š
   - ä¼˜å…ˆæœç´¢{current_time['year']}å¹´{current_time['month']}æœˆ{current_time['day']}æ—¥å‘å¸ƒçš„ä¿¡æ¯
   - å¦‚æœæ˜¯{current_time['day']}æ—¥ä¹‹å‰çš„æ¶ˆæ¯ï¼Œå¿…é¡»æ˜ç¡®æ ‡æ³¨å‘å¸ƒæ—¶é—´
   - ä½¿ç”¨"æœ€æ–°"ã€"åˆšåˆš"ã€"ä»Šæ—¥"ã€"æœ¬å°æ—¶"ç­‰å…³é”®è¯å¼ºåŒ–æœç´¢

3. **æŠ€æœ¯æ•°æ®ç±»**ï¼ˆæŠ€æœ¯æŒ‡æ ‡ã€é“¾ä¸Šæ•°æ®ã€ç»Ÿè®¡æ•°æ®ï¼‰ï¼š
   - æœç´¢{current_time['year']}å¹´{current_time['month']}æœˆ{current_time['day']}æ—¥çš„æœ€æ–°æŠ€æœ¯æŒ‡æ ‡
   - å¯¹äº24å°æ—¶å‘¨æœŸæ•°æ®ï¼Œç¡®ä¿æ•°æ®æˆªæ­¢æ—¶é—´ä¸æ—©äºæ˜¨æ—¥åŒä¸€æ—¶é—´

ğŸ¯ æœç´¢ç­–ç•¥ä¼˜åŒ–ï¼š
- åœ¨æœç´¢æŸ¥è¯¢ä¸­æ·»åŠ æ—¶é—´é™å®šè¯ï¼š"2025å¹´6æœˆ23æ—¥"ã€"ä»Šæ—¥"ã€"å®æ—¶"ã€"live"ã€"current"ã€"latest"
- å¯¹äºä»·æ ¼æŸ¥è¯¢ï¼Œä½¿ç”¨"real-time price"ã€"current quote"ã€"live data"
- éªŒè¯æ•°æ®æ—¶é—´æˆ³ï¼Œä¼˜å…ˆé€‰æ‹©å¸¦æœ‰æ˜ç¡®æ›´æ–°æ—¶é—´çš„æ•°æ®æº
- äº¤å‰éªŒè¯ï¼šå¯¹æ¯”3-4ä¸ªä¸åŒæ¥æºçš„æ•°æ®ç¡®ä¿å‡†ç¡®æ€§

ğŸ“‹ ç­”æ¡ˆæ ¼å¼è¦æ±‚ï¼š
1. **å¿…é¡»åŒ…å«æ•°æ®æ—¶é—´**ï¼šæ˜ç¡®æ ‡æ³¨"æˆªè‡³{current_time['year']}å¹´{current_time['month']}æœˆ{current_time['day']}æ—¥{current_time['hour']}:{current_time['minute']}"
2. **æ•°æ®æ–°é²œåº¦æ ‡è¯†**ï¼š
   - 10åˆ†é’Ÿå†…ï¼šâœ… å®æ—¶æ•°æ®
   - 30åˆ†é’Ÿå†…ï¼šâš¡ è¾ƒæ–°æ•°æ®  
   - 1å°æ—¶å†…ï¼šâ° ä¸€èˆ¬æ•°æ®
   - è¶…è¿‡1å°æ—¶ï¼šâš ï¸ å¯èƒ½è¿‡æ—¶
3. **æ¥æºå¯é æ€§**ï¼šä¼˜å…ˆå¼•ç”¨å®˜æ–¹/ä¸»æµå¹³å°æ•°æ®
4. **ç®€æ´ç²¾å‡†**ï¼š200-300å­—ï¼Œèšç„¦æ ¸å¿ƒé—®é¢˜ï¼Œé¿å…æ— å…³ä¿¡æ¯å»¶ä¼¸

âš ï¸ æ•°æ®è´¨é‡æ§åˆ¶ï¼š
- å¦‚æœæ‰¾åˆ°çš„æœ€æ–°æ•°æ®è¶…è¿‡é¢„æœŸæ—¶é—´èŒƒå›´ï¼Œæ˜ç¡®è¯´æ˜æ—¶é—´å·®è·
- å¯¹äºå¿«é€Ÿå˜åŒ–çš„æ•°æ®ï¼ˆå¦‚åŠ å¯†è´§å¸ï¼‰ï¼Œä¸¥æ ¼æ‰§è¡Œ10åˆ†é’Ÿæ—¶æ•ˆæ€§è¦æ±‚
- é‡åˆ°å†²çªæ•°æ®æ—¶ï¼Œé€‰æ‹©æ›´æ–°æ—¶é—´æœ€è¿‘ä¸”æ¥æºæ›´æƒå¨çš„ç‰ˆæœ¬
- å¿…é¡»åœ¨ç­”æ¡ˆå¼€å¤´æ ‡æ³¨æ•°æ®è·å–çš„å…·ä½“æ—¶é—´ç‚¹
- é—®é¢˜ä¸»é¢˜å†…å®¹å¦‚æœå’ŒæŸ¥è¯¢å®æ—¶ä»·æ ¼æ— å…³ï¼Œåˆ™è¿”å›çš„ç»“æœä¸­ä¸è¦åŒ…å«ä»»ä½•ä»·æ ¼ç›¸å…³ä¿¡æ¯ã€‚åªæœ‰åœ¨é—®é¢˜ä¸»é¢˜æ˜ç¡®è¦æ±‚æŸ¥è¯¢ä»·æ ¼æ—¶ï¼Œè¿”å›ç»“æœå†åŒ…å«ä»·æ ¼ä¿¡æ¯ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸Šæ—¶æ•ˆæ€§è¦æ±‚è¿›è¡Œæœç´¢å’Œä¿¡æ¯ç­›é€‰ã€‚
"""
            
            # ä½¿ç”¨é€Ÿç‡é™åˆ¶
            async with self.client_manager.openai_rate_limit():
                response = await self.client_manager.openai_client.responses.create(
                    model="gpt-4.1",
                    tools=[{
                        "type": "web_search_preview",
                        "search_context_size": question.search_context_size,
                        "user_location": {
                            "type": "approximate", 
                            "timezone": self.timezone
                        }
                    }],
                    input=search_prompt,
                    temperature=0.1
                )
            
            # æå–ç­”æ¡ˆ
            answer = response.output_text.strip() if hasattr(response, 'output_text') else str(response)
            
            search_time = time.time() - start_time
            logger.info(f"é—®é¢˜æœç´¢å®Œæˆï¼Œè€—æ—¶: {search_time:.2f}ç§’")
            
            return SearchResult(
                question=question,
                answer=answer,
                success=True,
                search_time=search_time
            )
            
        except Exception as e:
            search_time = time.time() - start_time
            logger.error(f"æœç´¢å¤±è´¥: {str(e)}")
            return SearchResult(
                question=question,
                answer="",
                success=False,
                error=str(e),
                search_time=search_time
            )
    
    async def search_questions_concurrently(self, questions: List[Question]) -> List[SearchResult]:
        """å¹¶å‘æœç´¢æ‰€æœ‰é—®é¢˜ï¼ˆå…¨å¼‚æ­¥ç‰ˆï¼‰"""
        # åˆ›å»ºæ‰€æœ‰æœç´¢ä»»åŠ¡
        tasks = [self.search_single_question(question) for question in questions]
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"æœç´¢ä»»åŠ¡å¤±è´¥: {str(result)}")
                processed_results.append(SearchResult(
                    question=questions[i],
                    success=False,
                    error=str(result)
                ))
            else:
                processed_results.append(result)
        
        return processed_results
    
    def format_results(self, results: List[SearchResult], total_time: float = 0) -> str:
        """æ ¼å¼åŒ–è¾“å‡ºç»“æœ"""
        output = []
        output.append("=" * 80)
        output.append(f"ğŸ“… æœç´¢æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        output.append("=" * 80)
        output.append("")
        
        # ç»Ÿè®¡ä¿¡æ¯
        success_count = sum(1 for r in results if r.success)
        output.append(f"ğŸ“Š æœç´¢ç›¸å…³ä¸»é¢˜ç”¨äºå›ç­”ç”¨æˆ·é—®é¢˜ï¼šæˆåŠŸ {success_count}/{len(results)} ä¸ªé—®é¢˜")
        output.append("")
        
        # è¯¦ç»†ç»“æœ
        for i, result in enumerate(results, 1):
            output.append(f"ã€é—®é¢˜ {i}ã€‘{result.question.main_question}")
            output.append("-" * 70)
            
            # æ˜¾ç¤ºå­é—®é¢˜
            if result.question.sub_questions:
                output.append("ğŸ“Œ å…·ä½“æ–¹é¢ï¼š")
                for j, sub_q in enumerate(result.question.sub_questions, 1):
                    output.append(f"   {j}. {sub_q}")
                output.append("")
            
            # æ˜¾ç¤ºæœç´¢ç»“æœ
            if result.success:
                output.append("ğŸ“„ æœç´¢ç»“æœï¼š")
                answer_lines = result.answer.split('\n')
                for line in answer_lines:
                    if line.strip():
                        output.append(f"   {line}")
            else:
                output.append(f"âŒ æœç´¢å¤±è´¥ï¼š{result.error}")
            
            output.append("")
            output.append("=" * 80)
            output.append("")
        
        return "\n".join(output)
    
    async def research_async(self, chat_history: str) -> str:
        """å¼‚æ­¥æ‰§è¡Œç ”ç©¶æµç¨‹ï¼ˆæ ¸å¿ƒæ–¹æ³•ï¼‰"""
        # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘ç”¨æˆ·è¯·æ±‚æ•°
        async with self._user_request_semaphore:
            total_start_time = time.time()
            
            try:
                # æ˜¾ç¤ºå½“å‰æ—¶é—´
                current_time = self.get_current_time()
                logger.info(f"å½“å‰æ—¶é—´ï¼š{current_time['datetime']}ï¼Œæ—¶åŒºä¸ºï¼š{self.timezone}")
                
                # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆé—®é¢˜ï¼ˆå¼‚æ­¥ï¼‰
                logger.info("å¼€å§‹ç”Ÿæˆç ”ç©¶é—®é¢˜...")
                questions = await self.generate_research_questions(chat_history)
                logger.info(f"å·²ç”Ÿæˆ {len(questions)} ä¸ªç ”ç©¶é—®é¢˜")
                
                # ç¬¬äºŒæ­¥ï¼šå¹¶å‘æœç´¢ï¼ˆå…¨å¼‚æ­¥ï¼‰
                logger.info("å¼€å§‹å¹¶å‘æœç´¢...")
                results = await self.search_questions_concurrently(questions)
                logger.info("æœç´¢å®Œæˆ")
                
                # è®¡ç®—æ€»è€—æ—¶
                total_time = time.time() - total_start_time
                
                # æ ¼å¼åŒ–å¹¶è¿”å›ç»“æœ
                return self.format_results(results, total_time)
                
            except Exception as e:
                logger.error(f"ç ”ç©¶è¿‡ç¨‹å‡ºé”™: {str(e)}")
                return f"ç ”ç©¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"

# å…¨å±€å®¢æˆ·ç«¯ç®¡ç†å™¨å®ä¾‹ï¼ˆç”¨äºæ¸…ç†ï¼‰
_global_client_manager: Optional[APIClientManager] = None

async def cleanup_clients():
    """æ¸…ç†å…¨å±€å®¢æˆ·ç«¯è¿æ¥"""
    global _global_client_manager
    if _global_client_manager:
        await _global_client_manager.close()

def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    # ç¤ºä¾‹èŠå¤©è®°å½•
    sample_chat_histories = [
        # ç®€å•æŸ¥è¯¢
        "ç”¨æˆ·ï¼šä»Šå¤©ä¸Šæµ·çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
        
        # ä¸­ç­‰å¤æ‚åº¦ - åŠ å¯†è´§å¸å¸‚åœº
        "ç”¨æˆ·ï¼šBTCæœ€è¿‘å‘å±•è¿‘å†µå¦‚ä½•ï¼Ÿé€‚åˆæŠ•èµ„å…¥åœºå—ï¼Ÿ",
        
        # è‚¡ç¥¨å¸‚åœºæŸ¥è¯¢
        "ç”¨æˆ·ï¼šç§‘æŠ€è‚¡æœ€è¿‘çš„è¡¨ç°å¦‚ä½•ï¼Ÿæœ‰å“ªäº›å€¼å¾—å…³æ³¨çš„å…¬å¸ï¼Ÿ",
        
        # é«˜å¤æ‚åº¦ - è¡Œä¸šåˆ†æ
        """ç”¨æˆ·ï¼šæˆ‘æ­£åœ¨è€ƒè™‘æŠ•èµ„æ–°èƒ½æºæ±½è½¦è¡Œä¸šï¼Œèƒ½å¸®æˆ‘åˆ†æä¸€ä¸‹è¿™ä¸ªè¡Œä¸šçš„ç°çŠ¶å’Œæœªæ¥è¶‹åŠ¿å—ï¼Ÿ
ç‰¹åˆ«æ˜¯æƒ³äº†è§£ï¼š
1. ä¸»è¦çš„å¸‚åœºç©å®¶å’Œä»–ä»¬çš„å¸‚åœºä»½é¢
2. æœ€æ–°çš„æŠ€æœ¯å‘å±•
3. æ”¿ç­–æ”¯æŒæƒ…å†µ
4. æŠ•èµ„é£é™©å’Œæœºä¼š"""
    ]
    
    async def async_main():
        try:
            # åˆ›å»ºç ”ç©¶åŠ©æ‰‹å®ä¾‹
            assistant = ResearchAssistant()
            
            # æ˜¾ç¤ºå½“å‰æ—¶é—´
            current_time = assistant.get_current_time()
            print(f"â° ç³»ç»Ÿå½“å‰æ—¶é—´ï¼š{current_time['datetime']}")
            print(f"ğŸ“… æ—¥æœŸï¼š{current_time['year']}å¹´{current_time['month']}æœˆ{current_time['day']}æ—¥ {current_time['weekday']}")
            print("="*80 + "\n")
            
            # é€‰æ‹©ä¸€ä¸ªç¤ºä¾‹è¿›è¡Œæµ‹è¯•
            chat_history = sample_chat_histories[1]  # ä½¿ç”¨åŠ å¯†è´§å¸çš„ä¾‹å­
            
            print("ğŸ“ èŠå¤©è®°å½•ï¼š")
            print(chat_history)
            print("\n" + "="*80 + "\n")
            
            # æ‰§è¡Œç ”ç©¶
            result = await assistant.research_async(chat_history)
            
            # è¾“å‡ºç»“æœ
            print(result)
            
        except ValueError as e:
            print(f"âŒ é…ç½®é”™è¯¯: {str(e)}")
            print("è¯·æ£€æŸ¥.envæ–‡ä»¶ä¸­çš„APIå¯†é’¥é…ç½®")
        except Exception as e:
            print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
        finally:
            # æ¸…ç†èµ„æº
            await cleanup_clients()
    
    # è¿è¡Œå¼‚æ­¥ä¸»å‡½æ•°
    asyncio.run(async_main())

if __name__ == "__main__":
    main()